#### 1. 介绍Hadoop、特点

##### 简介

Hadoop是一个分布式系统基础架构，主要是为了解决海量数据的存储和海量数据的分析计算问题。

1. Hadoop自诞生以来，主要有Hadoop 1.x、2.x、3.x三个系列多个版本；
2. Hadoop 1.x组成：HDFS（具有高可靠性、高吞吐量的分布式文件系统，用于数据存储），MapReduce（同时处理业务逻辑运算和资源的调度），Common（辅助工具，为其它Hadoop模块提供基础设施）；
3. Hadoop 2.x和Hadoop 3.x组成上无变化，和Hadoop 1.x相比，增加了YARN，分担了MapReduce的工作，组件包括：HDFS（具有高可靠性、高吞吐量的分布式文件系统，用于数据存储），MapReduce（处理业务逻辑运算），YARN（负责作业调度与集群资源管理），Common（辅助工具，为其它Hadoop模块提供基础设施）。

##### 特点

1. **高可靠性**：Hadoop底层维护多个数据副本，即使Hadoop某个计算元素或存储出现故障时，也不会大致数据的丢失
2. **高扩展性**：在集群间分配任务数据，可方便的扩展数以千计的节点
3. **高效性**：在MapReduce的思想下，Hadoop是并行工作，加快任务处理速度
4. **高容错性**：能够自动将失败的任务重新分配

#### 2. 介绍HDFS、优缺点、使用场景、作用

HDFS是一个文件系统，用于存储文件，通过目录树来定位文件。其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。

##### 优缺点

**优点**

1. **高容错性**：数据自动保存多个副本。它通过增加副本的形式，提高容错性。某一个副本丢失以后，它可以自动恢复。
2. **适合处理大数据**
   1. 数据规模：能够处理数据规模达到GB、TB、甚至PB级别的数据；
   2. 文件规模：能够处理百万规模以上的文件数量，数量相当之大。
3. **可构建在廉价机器上**，通过多副本机制，提高可靠性。

**缺点**

1. **不适合低延时数据访问**：比如毫秒级的存储数据，是做不到的。
2. **无法高效的对大量小文件进行存储**：存储大量小文件的话，它会占用NameNode大量的内存来存储文件目录和块信息。这样是不可取的，因为NameNode的内存总是有限的；小文件存储的寻址时间会超过读取时间，它违反了HDFS的设计目标。
3. 不支持**并发写入**、**文件随机修改**：一个文件只能有一个写，不允许多个线程同时写；仅支持数据append（追加），不支持文件的随机修改。

##### 使用场景

1. **海量数据存储**：HDFS可横向扩展，其存储的文件可以支持PB级别或更高级别的数据存储。
2. **高容错性**：数据保存多个副本，副本丢失后自动恢复。可构建在廉价的机器上，实现线性扩展。当集群增加新节点之后，namenode也可以感知，进行负载均衡，将数据分发和备份数据均衡到新的节点上。
3. **商用硬件**：Hadoop并不需要运行在昂贵且高可靠的硬件上。它是设计运行在商用硬件（廉价商业硬件）的集群上的。
4. **大文件存储**：HDFS采用数据块的方式存储数据，将数据物理切分成多个小的数据块。所以再大的数据，切分后，大数据变成了很多小数据。用户读取时，重新将多个小数据块拼接起来。
5. **一次写入多次读取**：HDFS是设计成适应一次写入，多次读出的场景，且不支持文件的修改。正因为如此，HDFS适合用来做大数据分析的底层存储服务，并不适合用来做.网盘等应用，因为，修改不方便，延迟大，网络开销大，成本太高。

##### HDFS作用

HDFS在Hadoop中的作用是为**海量的数据提供了存储**，能提供**高吞吐量的数据访问**，HDFS**有高容错性**的特点，并且设计用来**部署在低廉的硬件上**；而且它提供高吞吐量来访问应用程序的数据，适合那些有着超大数据集的应用程序。对外部客户机而言，HDFS就像一个传统的分级文件系统。可以创建、删除、移动或重命名文件，等等。但是HDFS的架构是基于一组特定的节点构建的，这是由它自身的特点决定的。这些节点包括NameNode（仅一个，HA两个），它在HDFS内部提供元数据服务；DataNode，它为HDFS提供存储块。

#### 3. 介绍MapReduce、优缺点

##### 简介

Hadoop MapReduce是一个软件框架，基于该框架能够容易地编写应用程序，这些应用程序能够运行在由上千个商用机器组成的大集群上，并以**一种可靠的，具有容错能力的方式并行地处理上TB级别的海量数据集。**

MapReduce 是一个**分布式运算程序的编程框架**，它的核心功能是**将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序**，并发运行在一个 Hadoop 集群上。

MapReduce的**核心思想是将用户编写的逻辑代码和架构中的各个组件整合成一个分布式运算程序，实现一定程序的并行处理海量数据，提高效率**。海量数据难以在单机上处理，而一旦将单机版程序扩展到集群上进行分布式运行势必将大大增加程序的复杂程度。引入MapReduce架构，开发人员可以将精力集中于数据处理的核心业务逻辑上，而将分布式程序中的公共功能封装成框架,以降低开发的难度。

一个完整的mapreduce程序有三类实例进程

1. **MRAppMaster**：负责整个程序的协调过程
2. **MapTask**：负责map阶段的数据处理
3. **ReduceTask**：负责reduce阶段的数据处理

##### 优缺点

**优点**

1. **MapReduce 易于编程**：它简单的实现一些接口，就可以完成一个分布式程序，这个分布式程序可以分布到大量廉价的 PC 机器上运行。也就是说你写一个分布式程序，跟写一个简单的串行程序是一模一样的。就是因为这个特点使得 MapReduce 编程变得非常流行。
2. **良好的扩展性**：当你的计算资源不能得到满足的时候，你可以通过简单的增加机器来扩展它的计算能力。
3. **高容错性**：MapReduce 设计的初衷就是使程序能够部署在廉价的 PC 机器上，这就要求它具有很高的容错性。比如其中一台机器挂了，它可以把上面的计算任务转移到另外一个节点上运行， 不至于这个任务运行失败，而且这个过程不需要人工参与，而完全是由 Hadoop 内部完成的。
4. 适合 PB 级以上**海量数据的离线处理**：可以实现上千台服务器集群并发工作，提供数据处理能力。

**缺点**

1. **不擅长实时计算**：MapReduce无法像MySQL一样，在毫秒或者秒级内返回结果。
2. **不擅长流式计算**：流式计算的输入数据是动态的，而MapReduce的输入数据集是静态的，不能动态变化。这是因为MapReduce 自身的设计特点决定了数据源必须是静态的。
3. **不擅长 DAG**（有向无环图）计算：多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。在这种情况下，MapReduce并不是不能做，而是使用后，每个MapReduce作业的输出结果都会写入到磁盘， 会造成大量的磁盘 IO，导致性能非常的低下。

#### 4. 介绍下YARN、优势

> 介绍YARN，可以先考虑下面两个问题：
>
> 1. 如何管理集群资源？
> 2. 如何给任务合理分配资源？

##### 简介

**YARN是一个资源调度平台，负责为运算程序提供服务器运算资源，**相当于一个分布式的操作系统平台，而MapReduce等运算程序则相当于运行于操作系统之上的应用程序。YARN 作为一个资源管理、任务调度的框架，主要包含ResourceManager、NodeManager、ApplicationMaster和Container模块。

ResourceManager（RM）主要作用如下：

1. 处理客户端请求
2. 监控NodeManager
3. 启动或监控ApplicationMaster
4. 资源的分配与调度

NodeManager（NM）主要作用如下：

1. 管理单个节点上的资源
2. 处理来自ResourceManager的命令
3. 处理来自ApplicationMaster的命令

ApplicationMaster（AM）作用如下：

1. 为应用程序申请资源并分配给内部的任务
2. 任务的监督与容错

Container：

1. Container是YARN中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等。

##### 优势

1. 解决了单点故障问题，由于每一个任务由一个AppMaster进行调度，且可进行AppMaster出错重试，从而使单点故障影响到多个任务进行问题不存在。
2. 解决了单点压力过大问题，每一个任务由一个AppMaster进行调度，而每一个AppMaster都是由集群中资源较为充足的结点进行启动，调度任务，起到一个负载均衡的作用。
3. 完成了资源管理和任务调度的解耦，Yarn只负责对集群资源的管理，各个计算框架只要继承了AppMaster，就可以共同使用Yarn资源管理，更加充分地利用集群资源。

在Hadoop 1.x版本时，JobTracker和TaskTracker是常服务，资源管理和任务调度的耦合，而在Hadoop 2.x版本之后，**Yarn将二者分离，只有资源管理成为了常服务，而任务调度则变成只有任务在调度时，才启用的临时服务。**

#### 5. 介绍Zookeeper、特点、作用、优缺点、应用场景

Zookeeper是一个开源的分布式的，**为分布式应用提供协调服务**的Apache项目。

Zookeeper从设计模式角度来理解，是一个**基于观察者模式设计**的分布式服务管理框架，它负责存储和管理大家都关心的数据，然后接受观察者的注册，一旦这些数据的状态发生了变化，Zookeeper就负责通知已经在Zookeeper上注册的那些观察者做出相应的反应。

Zookeeper提供的服务包括：统一命名服务、统一配置管理、统一集群管理、服务器节点动态上下线、软负载均衡等。**它致力于为那些高吞吐的大型分布式系统提供一个高性能、高可用、且具有严格顺序访问控制能力的分布式协调服务。**

##### 特点

1. **顺序一致性**：从一个客户端发起的事务请求，最终都会严格按照其发起顺序被应用到Zookeeper中；对于来自客户端的每个更新请求，Zookeeper都会分配一个全局唯一的递增ID(zxid)，这个ID反映了所有事务请求的先后顺序。
2. **原子性**：所有事务请求的处理结果在整个集群中所有机器上都是一致的
3. **最终一致性**：所有客户端看到的服务端数据模型都是一致的；
4. **可靠性**：一旦服务端成功应用了一个事务，则其引起的改变会一直保留，直到被另外一个事务所更改,如果消息被到一台服务器接受，那么它将被所有的服务器接受。
5. **实时性**：一旦一个事务被成功应用后，Zookeeper可以保证客户端立即可以读取到这个事务变更后的最新状态的数据。
5. **等待无关（wait-free）**：慢的或者失效的client不得干预快速的client的请求，使得每个client都能有效的等待。由于Zookeeper的所有更新和删除都是基于事务的，所以其在读多写少的应用场景中有着很高的性能表现。ZooKeeper将数据存全量储在内存中以保持高性能，并通过服务集群来实现高可用。

##### 作用

Zookeeper作用包括存储数据（文件系统）和监听（监听通知机制）

##### 优缺点

**优点：**

1. 分布式协调过程简单
2. 同步：zk高度同步，这意味着服务器进程之间既存在互斥又存在合作，同步有助于ApacheHBase进行配置管理。
3. 有序消息：zk跟踪一个数字，表示每个更新的顺序，保证消息有序
4. 序列化：根据具体规则，zk对数据进行编码。另外，它还可确保我们的应用程序始终如一地运行。但是，在MapReduce中，我们使用此方法（序列化）来协调队列以执行正在运行的线程
5. 速度：在读请求多的情况下，能以很快的速度运行
6. 可扩展性：此外，可以通过部署更多机器来加强zk的性能
7. 有序性有何优势？：众所周知，zk中的消息是有序的。所以，为了实现更高级别的抽象，需要有序性。这就是有序性对我们有利的方式
8. 快：在读多的情况下，zk会非常快
9. 可靠性：zk非常可靠，因为一旦zk更新了，更新后的数据会一直保持，直到被覆盖更新
10. 原子性：zk只有两种情况，要么全部成功，要么全部失败，没有中间状态的情况
11. 实时性：zk保证在一定时间段内，客户端最终一定能从服务器上读到最新的数据状态

**缺点**

1. 增加新的zk服务器时可能导致数据丢失：在现有服务器中，当新zk服务器数量超过zk服务中已存在的数量时数据会丢失。同时，向zk服务发出Start命令，新服务器可能形成仲裁
2. 不能迁移：在没有用户干预的情况下，zk服务器无法从版本3.4迁移到3.3，然后再迁移到3.4。
3. 节点数：要求3或5个这样奇数个zk节点（要求奇数是为了保证选举的正常进行因为leader选举要求可用节点数量>总节点数/2，防止脑裂造成集群不可用。同时在容错能力相同的情况下，奇数个节点更节省资源）
4. 机架感知复制：目前，它不支持机架放置和感知
5. 缩容：不支持减少pod的数量，以防止意外数据丢失
6. 磁盘变更：不支持在初始部署后更改volume要求，以防止重新分配意外丢失数据
7. 虚拟网络：当服务部署在虚拟网络上时，如果没有完全重新安装，服务可能无法切换到主机网络。另外，对于尝试从主机切换到虚拟网络，它们是相同的情况
8. Kerberos：在虚拟网络上，它目前不支持启用Kerberos
9. 支持有限：对跨群集方案的支持非常有限。但是，没有CP系统会一直支持跨集群。虽然我们可以说consul似乎在这方面做得更好

##### 应用场景

1. 数据的发布/订阅

   数据的发布/订阅系统，通常也用作配置中心。在分布式系统中，你可能有成千上万个服务节点，如果想要对所有服务的某项配置进行更改，由于数据节点过多，你不可逐台进行修改，而应该在设计时采用统一的配置中心。之后发布者只需要将新的配置发送到配置中心，所有服务节点即可自动下载并进行更新，从而实现配置的集中管理和动态更新。Zookeeper通过Watcher机制可以实现数据的发布和订阅。分布式系统的所有的服务节点可以对某个ZNode注册监听，之后只需要将新的配置写入该ZNode，所有服务节点都会收到该事件。

2. 命名服务

   在分布式系统中，通常需要一个全局唯一的名字，如生成全局唯一的订单号等，Zookeeper可以通过顺序节点的特性来生成全局唯一ID，从而可以对分布式系统提供命名服务。

3. Master选举

   分布式系统一个重要的模式就是主从模式(Master/Salves)，Zookeeper可以用于该模式下的Matser选举。可以让所有服务节点去竞争性地创建同一个ZNode，由于Zookeeper不能有路径相同的ZNode，必然只有一个服务节点能够创建成功，这样该服务节点就可以成为Master节点。

4. 分布式锁

   可以通过Zookeeper的临时节点和Watcher机制来实现分布式锁，这里以排它锁为例进行说明：分布式系统的所有服务节点可以竞争性地去创建同一个临时ZNode，由于Zookeeper不能有路径相同的ZNode，必然只有一个服务节点能够创建成功，此时可以认为该节点获得了锁。其他没有获得锁的服务节点通过在该ZNode上注册监听，从而当锁释放时再去竞争获得锁。锁的释放情况有以下两种：

   1. 当正常执行完业务逻辑后，客户端主动将临时ZNode删除，此时锁被释放；
   2. 当获得锁的客户端发生宕机时，临时ZNode会被自动删除，此时认为锁已经释放。 当锁被释放后，其他服务节点则再次去竞争性地进行创建，但每次都只有一个服务节点能够获取到锁，这就是排他锁。

5. 集群管理

   Zookeeper还能解决大多数分布式系统中的问题：如可以通过创建临时节点来建立心跳检测机制。如果分布式系统的某个服务节点宕机了，则其持有的会话会超时，此时该临时节点会被删除，相应的监听事件就会被触发。分布式系统的每个服务节点还可以将自己的节点状态写入临时节点，从而完成状态报告或节点工作进度汇报。通过数据的订阅和发布功能，Zookeeper还能对分布式系统进行模块的解耦和任务的调度。通过监听机制，还能对分布式系统的服务节点进行动态上下线，从而实现服务的动态扩容事务操作

6. 事务操作

   在ZooKeeper中，能改变ZooKeeper服务器状态的操作称为事务操作。一般包括数据节点创建与删除、数据内容更新和客户端会话创建与失效等操作。对应每一个事务请求，ZooKeeper都会为其分配一个全局唯一的事务ID，用ZXID表示，通常是一个64位的数字。每一个ZXID对应一次更新操作，从这些ZXID中可以间接地识别出ZooKeeper处理这些事务操作请求的全局顺序。

#### 6. 介绍Hive、优缺点、作用

##### 简介

Hive是Hadoop生态系统中比不可少的一个工具，**它提供了一种SQL(结构化查询语言)方言，可以查询存储在Hadoop分布式文件系统（HDFS）中的数据或其他和Hadoop集成的文件系统，**如MapR-FS、Amazon的S3和像HBase（Hadoop数据仓库）和Cassandra这样的数据库中的数据。

大多数数据仓库应用程序都是使用关系数据库进行实现的，并使用SQL作为查询语言。**Hive降低了将这些应用程序转移到Hadoop系统上的难度**。凡是会使用SQL语言的开发人员都可以很轻松的学习并使用Hive。另外，Hive更便于开发人员将基于SQL的应用程序转移到Hadoop中。

##### 优缺点

**优点**

1. 操作接口采用类SQL语法，提供快速开发的能力（简单、容易上手）。
2. 避免了去写MapReduce，减少开发人员的学习成本。
3. Hive的执行延迟比较高，因此Hive常用于数据分析，对实时性要求不高的场合。
4. Hive优势在于处理大数据，对于处理小数据没有优势，因为Hive的执行延迟比较高。
5. Hive支持用户自定义函数，用户可以根据自己的需求来实现自己的函数。

**缺点**

1. Hive的HQL表达能力有限
   1. 迭代式算法无法表达
   2. 数据挖掘方面不擅长，由于MapReduce数据处理流程的限制，效率更高的算法却无法实现。
2. Hive的效率比较低
   1. Hive自动生成的MapReduce作业，通常情况下不够智能化
   2. Hive调优比较困难，粒度较粗

**Hive不是一个完整的数据库**。Hadoop以及HDFS的设计本身约束和局限性地限制了Hive所能胜任的工作。**其中最大的限制就是Hive不支持记录级别的更新、插入或者删除操作。**但是用户可以通过查询生成新表或者将查询结果导入到文件中。同时，因为Hadoop是面向批处理的系统，而MapReduce任务（job）的启动过程需要消耗较长的时间，所以Hive**查询延时比较严重**。传统数据库中在秒级别可以完成的查询，在Hive中，即使数据集相对较小，往往也需要执行更长的时间。

##### 作用

Hive是由Facebook开源用于解决海量结构化日志的数据统计工具。

Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类SQL查询功能。**Hive的本质是将HQL转化成MapReduce程序。**

1. Hive处理的数据存储在HDFS
2. Hive分析数据底层的实现是MapReduce
3. 执行程序运行在Yarn上

#### 7. 介绍Flume、优缺点、应用场景

##### 简介

Flume是Cloudera提供的一个高可用的，高可靠的，**分布式的海量日志采集、聚合和传输的系统。**Flume可以收集例如日志，事件等数据资源，并将这些数量庞大的数据从各项数据资源中集中起来存储的工具/服务。flume具有高可用，分布式，配置工具，其设计的**原理是基于数据流**（流式架构，灵活简单），如日志数据从各种网站服务器上汇集起来存储到HDFS，HBase等集中存储器中。

**Flume最主要的作用是实时读取服务器本地磁盘的数据，将数据写入HDFS或Kafka等。**

##### 优缺点

**优点**

1. Flume可以将应用产生的数据存储到任何集中存储器中，比如HDFS,HBase。
2. 当收集数据的速度超过将写入数据的时候，也就是当收集信息遇到峰值时，这时候收集的信息非常大，甚至超过了系统的写入数据能力，这时候，Flume会在数据生产者和数据收容器间做出调整，保证其能够在两者之间提供一共平稳的数据。
3. 提供上下文路由特征。
4. Flume的管道是基于事务，保证了数据在传送和接收时的一致性。
5. Flume是可靠的，容错性高的，可升级的，易管理的,并且可定制的。
6. 实时性，Flume有一个好处可以实时的将分析数据并将数据保存在数据库或者其他系统中。

**缺点**

Flume的配置很繁琐，source，channel，sink的关系在配置文件里面交织在一起，不便于管理。

##### 应用场景

1. **电子商务网站**：比如我们在做一个电子商务网站，然后我们想从消费用户中访问点特定的节点区域来分析消费者的行为或者购买意图。这样我们就可以更加快速的将他想要的推送到界面上，实现这一点，我们需要将获取到的她访问的页面以及点击的产品数据等日志数据信息收集并移交给Hadoop平台上去分析，而Flume正是帮我们做到这一点。
2. **内容推送**：现在流行的内容推送，比如广告定点投放以及新闻私人定制也是基于此。
3. **ETL工具**：可以利用插件把关系型数据实时增量的导入到Hdfs外部数据源。

#### 8. 介绍Kafka，作用、使用场景、特点、优缺点

**Kafka是一种分布式、高吞吐量的分布式发布订阅消息系统**，它可以处理消费者规模的网站中的所有动作流数据，主要应用于大数据实时处理领域。简单地说，Kafka就相比是一个邮箱，生产者是发送邮件的人，消费者是接收邮件的人，Kafka就是用来存东西的，只不过它提供了一些处理邮件的机制。

##### 作用

1. 发布和订阅消息流
2. 以容错的方式记录消息流，kafka以文件的方式来存储消息流
3. 可以在消息发布的时候进行处理

**优势**

1. 高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒；
2. 可扩展性：kafka集群支持热扩展；
3. 持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失；
4. 容错性：允许集群中节点故障（若副本数量为n,则允许n-1个节点故障）；
5. 高并发：支持数千个客户端同时读写。

##### 使用场景

> 在系统或应用程序之间构建可靠的用于传输实时数据的管道，消息队列功能
>
> 构建实时的流数据处理程序来变换或处理数据流，数据处理功能

1. 日志收集：一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer；
2. 消息系统：解耦生产者和消费者、缓存消息等；
3. 用户活动跟踪：kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后消费者通过订阅这些topic来做实时的监控分析，亦可保存到数据库；
4. 运营指标：kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告；
5. 流式处理：比如Spark streaming和Flink。

##### 特点

1. **高吞吐量、低延迟**：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒；
2. **可扩展性**：kafka集群支持热扩展；
3. **持久性、可靠性**：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失；
4. **容错性**：允许集群中节点故障（若副本数量为n,则允许n-1个节点故障）；
5. **高并发**：支持数千个客户端同时读写。

##### 优缺点

**优点**

1. 支持多个生产者和消费者
2. 支持broker的横向拓展
3. 副本集机制，实现数据冗余，保证数据不丢失
4. 通过topic将数据进行分类
5. 通过分批发送压缩数据的方式，减少数据传输开销，提高吞高量
6. 支持多种模式的消息
7. 基于磁盘实现数据的持久化
8. 高性能的处理}信息，在大数据的情况下，可以保证亚秒级的消息延迟
9. 一个消费者可以支持多种topic的消息
10. 对CPU和内存的消耗比较小
11. 对网络开销也比较小
12. 支持跨数据中心的数据复制
13. 支持镜像集群

**缺点**

1. 由于是批量发送，所以数据达不到真正的实时
2. 对于mqtt协议不支持
3. 不支持物联网传感数据直接接入
4. 只能支持统一分区内消息有序，无法实现全局消息有序
5. 监控不完善，需要安装插件
6. 需要配合zookeeper进行元数据管理
7. 会丢失数据，并且不支持事务
8. 可能会重复消费数据，消息会乱序，可用保证一个固定的partition内部的消息是有序的，但是一个topic有多个partition的话，就不能保证有序了，需要zookeeper的支持，topic一般需要人工创建，部署和维护一般都比mq高

#### 9. 介绍HBase、优缺点、使用场景

HBase是**一种分布式、可扩展、支持海量数据存储的非关系型分布式数据库**，它参考了谷歌的BigTable建模，主要**用来存储非结构化和半结构化的松散数据**，实现的编程语言为Java。它是Apache软件基金会的Hadoop项目的一部分，运行于HDFS文件系统之上，为Hadoop提供类似于BigTable规模的服务。因此，它可以容错地存储海量稀疏的数据。

HBase的目标是处理非常庞大的表，可以通过水平扩展的方式，利用廉价计算机集群处理由超过10亿行数据和数百万列元素组成的数据表。

##### 应用场景

1. 交通方面：船舶GPS信息，全长江的船舶GPS信息，每天有1千万左右的数据存储。
2. 金融方面：消费信息、贷款信息、信用卡还款信息等
3. 电商方面：电商网站的交易信息、物流信息、游览信息等
4. 电信方面：通话信息、语音详单等

##### 优缺点

**优点**

1. 海量存储：Hbase适合存储PB级别的海量数据，在PB级别的数据以及采用廉价PC存储的情况下，能在几十到百毫秒内返回数据。这与Hbase的极易扩展性息息相关。正式因为Hbase良好的扩展性，才为海量数据的存储提供了便利。
2. 列式存储：这里的列式存储其实说的是列族（ColumnFamily）存储，Hbase是根据列族来存储数据的。列族下面可以有非常多的列，列族在创建表的时候就必须指定。
3. 极易扩展：Hbase的扩展性主要体现在两个方面，一个是基于上层处理能力（RegionServer）的扩展，一个是基于存储的扩展（HDFS）。通过横向添加RegionSever的机器，进行水平扩展，提升Hbase上层的处理能力，提升Hbsae服务更多Region的能力。(RegionServer的作用是管理region、承接业务的访问，这个后面会详细的介绍通过横向添加Datanode的机器，进行存储层扩容，提升Hbase的数据存储能力和提升后端存储的读写能力。)
4. 高并发（多核）：由于目前大部分使用Hbase的架构，都是采用的廉价PC，因此单个IO的延迟其实并不小，一般在几十到上百ms之间。这里说的高并发，主要是在并发的情况下，Hbase的单个IO延迟下降并不多。能获得高并发、低延迟的服务。
5. 稀疏：稀疏主要是针对Hbase列的灵活性，在列族中，你可以指定任意多的列，在列数据为空的情况下，是不会占用存储空间的。

**缺点**

1. 原生不支持SQL：SQL查询也是HBase的一个弱项，虽然HBase是一个非关系型数据库但是它不支持SQL语句，不过这块可以通过引入Phoenix解决，Phoenix是专为HBase设计的SQL层。
2. 原生不支持二级索引：单一RowKey固有的局限性决定了它不可能有效地支持多条件查询，只支持按照Row key来查询，因此正常情况下对非Rowkey列做查询比较慢。所以，我们一般会选择一个HBase二级索引解决方案，目前比较成熟的解决方案是Phoenix，此外还可以选择Elasticsearch/Solr等搜索引擎自己设计实现。
3. 暂时不能支持Master server的故障切换, 当Master宕机后, 整个存储系统就会挂掉
4. 数据分析能力弱：数据分析是HBase的弱项，比如聚合运算、多维度复杂查询、多表关联查询等。所以，我们一般在HBase之上架设Phoenix或Spark等组件，增强HBase数据分析处理的能力。

#### 10. Spark特点、使用场景

**Spark 是一种基于内存的快速、通用、可扩展的大数据分析计算引擎。**

##### 特点

1. **快**：与Hadoop的MapReduce相比，Spark基于内存的运算要快100倍以上，基于硬盘的运算也要快10倍以上。Spark实现了高效的DAG执行引擎，可以通过基于内存来高效处理数据流。计算的中间结果是存在于内存中的。
2. **易用**：Spark支持Java、Python和Scala的API，还支持超过80种高级算法，使用户可以快速构建不同的应用。而且Spark支持交互式的Python和Scala的Shell，可以非常方便地在这些Shell中使用Spark集群来验证解决问题的方法。
3. **通用**：Spark提供了统一的解决方案。Spark可以用于，交互式查询(Spark SQL)、实时流处理(Spark Streaming)、机器学习(Spark MLlib)和图计算(Graphx)。这些不同类型的处理都可以在同一个应用中无缝使用。减少了开发和维护的人力成本和部署平台的物力成本。
4. **兼容性**：Spark可以非常方便地与其他的开源产品进行融合。比如，Spark可以使用Hadoop的YARN和Apache Mesos作为它的资源管理和调度器，并且可以处理所有Hadoop支持的数据，包括HDFS、HBase等。这对于已经部署Hadoop集群的用户特别重要，因为不需要做任何数据迁移就可以使用Spark的强大处理能力。

##### 使用场景

大数据场景主要有以下几种类型：

1. **复杂的批处理**（BatchDataProcessing），偏重点在于处理。海量数据的能力，至于处理速度可忍受，通常的时间可能是在数十分钟到数小时；
2. **基于历史数据的交互式查询**（InteractiveQuery），通常的时间在数十秒到数十分钟之间；
3. **基于实时数据流的大数据处理**（StreamingDataProcessing），通常在数百毫秒到数秒之间；

对于上述的情况，不使用Spark来处理的框架如下：

1. 第一种情况可以用Hadoop的MapReduce来进行批量海量数据处理
2. 第二种情况可以Impala、Kylin进行交互式查询
3. 第三中情况可以用Storm分布式处理框架处理实时流式数据

使用Spark来进行处理：

1. 第一种情况使用SparkCore解决
2. 第二种情况使用SparkSQL解决
3. 第三种情况使用SparkStreaming解决

综上所述，Spark使用场景如下：

1. Spark是基于内存的迭代计算框架，适用于需要多次操作特定数据集的应用场合。需要反复操作的次数越多，所需读取的数据量越大，受益越大，数据量小但是计算密集度较大的场合，受益就相对较小；
2. 由于RDD的特性，Spark不适用那种异步细粒度更新状态的应用，例如web服务的存储或者是增量
3. 的web爬虫和索引。就是对于那种增量修改的应用模型不适合；
4. 数据量不是特别大，但是要求实时统计分析需求 ；

满足以上条件的均可采用Spark技术进行处理，在实际应用中，目前大数据在互联网公司主要应用在广告、报表、推荐系统等业务上，在广告业务方面需要大数据做应用分析、效果分析、定向优化等，在推荐系统方面则需要大数据优化相关排名、个性化推荐以及热点点击分析等。

这些应用场景的普遍特点是计算量大、效率要求高，Spark恰恰可以满足这些要求，该项目一经推出便受到开源社区的广泛关注和好评，并在近两年内发展成为大数据处理领域炙手可热的开源项目。

Spark使用Scala语言进行实现，它是一种面向对象、函数式编程语言，能够像操作本地集合对象一样轻松地操作分布式数据集，具有运行速度快、易用性好、通用性强以及随处运行等特点，适合大多数批处理工作，并已成为大数据时代企业大数据处理优选技术，其中有代表性企业有腾讯、Yahoo、淘宝以及优酷土豆等。

#### 11.区别

##### Spark or Hadoop

1. Hadoop MapReduce由于其设计初衷并不是为了满足循环迭代式数据流处理，**因此在多并行运行的数据可复用场景中存在诸多计算效率等问题**。所以Spark应运而生，Spark就是在传统的MapReduce计算框架的基础上，利用其计算过程的优化，从而大大**加快了数据分析、挖掘的运行和读写速度**，并将计算单元缩小到更适合并行计算和重复使用的RDD计算模型。
2. 机器学习中ALS、凸优化梯度下降等。这些都需要**基于数据集或者数据集的衍生数据反复查询反复操作**。MR这种模式不太合适，即使多MR串行处理，性能和时间也是一个问题。数据的共享依赖于磁盘。另外一种是交互式数据挖掘，MR显然不擅长。而**Spark所基于的scala语言恰恰擅长函数的处理。**
3. Spark是一个分布式数据快速分析项目。它的核心技术是**弹性分布式数据集**（ResilientDistributedDatasets），提供了比MapReduce丰富的模型，可以快速在内存中对数据集进行多次迭代，来支持复杂的数据挖掘算法和图形计算算法。
4. ==Spark和Hadoop的根本差异是多个作业之间的数据通信问题:Spark多个作业之间数据通信是基于内存，而Hadoop是基于磁盘==
5. SparkTask的启动时间快。Spark采用fork线程的方式，而Hadoop采用创建新的进程的方式。
6. Spark只有在shuffle的时候将数据写入磁盘，而Hadoop中多个MR作业之间的数据交互都要依赖于磁盘交互
7. Spark的缓存机制比HDFS的缓存机制高效

经过上面的比较，我们可以看出在绝大多数的数据计算场景中，Spark确实会比MapReduce更有优势。**但是Spark是基于内存的，所以在实际的生产环境中，由于内存的限制，可能会由于内存资源不够导致Job执行失败**，此时，MapReduce其实是一个更好的选择，所以Spark并不能完全替代MR。

##### Spark or Flink

1. 数据模型

   1. spark采用RDD模型，sparkstreaming的DStream实际上也就是一组组小批数据RDD的集合
   2. flink基本数据模型是数据流，以及事件（Event）序列
2. 运行时架构
   1. spark是批计算，将DAG划分为不同的stage，一个完成后才可以计算下一个
   2. flink是标准的流执行模式，一个事件在一个节点处理完后可以直接发往下一个节点进行处理
3. 状态
   1. spark本身是无状态的，所以我们可以把它看成一个rdd一个算子一个rdd的去处理，就是说可以看成分段处理。
   2. flink是事件驱动型应用是一类具有状态的应用，把它看成一个个event记录去处理，当遇到窗口时会进行阻塞等待，窗口的聚合操作是无状态的。过了窗口后DataStream的算子聚合操作就是有状态的操作，所以flink要把聚合操作都放到窗口操作之前，才能进行无状态的聚合操作。

主要考虑的是flink的低延迟、高吞吐量和对流式数据应用场景更好的支持；另外，flink可以很好地处理乱序数据，而且可以保证exactly-once的状态一致性。